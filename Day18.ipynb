{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b3135a-a168-4204-ab0a-80d171fec8f6",
   "metadata": {},
   "source": [
    "# Simple Implimentation of RNN from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feab1b6b-947c-4ce4-98a3-aee8c03ab5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Defining activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1 - np.tanh(x)**2\n",
    "\n",
    "# Defining the RNN class\n",
    "class SimpleRNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # Initializing weights\n",
    "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01  # input -> hidden\n",
    "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # hidden -> hidden\n",
    "        self.Why = np.random.randn(output_size, hidden_size) * 0.01  # hidden -> output\n",
    "\n",
    "        # Initializing biases\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        inputs: list of input vectors (each input_size x 1)\n",
    "        \"\"\"\n",
    "        self.last_inputs = inputs\n",
    "        self.last_hs = {0: np.zeros((self.hidden_size, 1))}  # initial hidden state\n",
    "\n",
    "        for t, x in enumerate(inputs):\n",
    "            prev_h = self.last_hs[t]\n",
    "            h = tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, prev_h) + self.bh)\n",
    "            self.last_hs[t + 1] = h\n",
    "\n",
    "        # Final output\n",
    "        y = np.dot(self.Why, self.last_hs[len(inputs)]) + self.by\n",
    "        return y\n",
    "\n",
    "    def backward(self, d_y, learning=True):\n",
    "        \"\"\"\n",
    "        Backward pass\n",
    "        d_y: gradient on output\n",
    "        \"\"\"\n",
    "        n = len(self.last_inputs)\n",
    "        \n",
    "        # Gradients initialization\n",
    "        dWhy = np.dot(d_y, self.last_hs[n].T)\n",
    "        dby = d_y\n",
    "\n",
    "        dWxh = np.zeros_like(self.Wxh)\n",
    "        dWhh = np.zeros_like(self.Whh)\n",
    "        dbh = np.zeros_like(self.bh)\n",
    "\n",
    "        dh_next = np.zeros((self.hidden_size, 1))\n",
    "\n",
    "    \n",
    "        for t in reversed(range(n)):\n",
    "            h = self.last_hs[t+1]\n",
    "            prev_h = self.last_hs[t]\n",
    "\n",
    "            dh = np.dot(self.Why.T, d_y) + dh_next  # backprop into h\n",
    "            dh_raw = dtanh(h) * dh\n",
    "\n",
    "            dbh += dh_raw\n",
    "            dWxh += np.dot(dh_raw, self.last_inputs[t].T)\n",
    "            dWhh += np.dot(dh_raw, prev_h.T)\n",
    "\n",
    "            dh_next = np.dot(self.Whh.T, dh_raw)\n",
    "\n",
    "    \n",
    "        if learning:\n",
    "            for param, dparam in zip(\n",
    "                [self.Wxh, self.Whh, self.Why, self.bh, self.by],\n",
    "                [dWxh, dWhh, dWhy, dbh, dby]\n",
    "            ):\n",
    "                param -= self.lr * dparam\n",
    "\n",
    "    def train(self, inputs, target):\n",
    "        \"\"\"\n",
    "        inputs: list of inputs\n",
    "        target: target output\n",
    "        \"\"\"\n",
    "        output = self.forward(inputs)\n",
    "        loss = np.square(output - target).sum()  # simple MSE loss\n",
    "        d_y = 2 * (output - target)  # derivative of loss w.r.t output\n",
    "        self.backward(d_y)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        output = self.forward(inputs)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac45108d-56b7-49b9-b206-3d0e645eedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 87.4627\n",
      "Epoch 100 Loss: 3.3846\n",
      "Epoch 200 Loss: 8.2014\n",
      "Epoch 300 Loss: 4.7297\n",
      "Epoch 400 Loss: 10.0501\n",
      "Epoch 500 Loss: 0.2479\n",
      "Epoch 600 Loss: 0.0001\n",
      "Epoch 700 Loss: 0.0000\n",
      "Epoch 800 Loss: 0.0000\n",
      "Epoch 900 Loss: 0.0000\n",
      "Prediction for 2+3: 6.379563412931214\n"
     ]
    }
   ],
   "source": [
    "# Creating the RNN\n",
    "rnn = SimpleRNN(input_size=1, hidden_size=10, output_size=1, learning_rate=0.01)\n",
    "\n",
    "# Training data: sequence -> sum\n",
    "dataset = [\n",
    "    ([np.array([[1]]), np.array([[2]])], np.array([[3]])),  # 1+2=3\n",
    "    ([np.array([[0]]), np.array([[5]])], np.array([[5]])),  # 0+5=5\n",
    "    ([np.array([[3]]), np.array([[4]])], np.array([[7]])),  # 3+4=7\n",
    "    ([np.array([[2]]), np.array([[1]])], np.array([[3]]))   # 2+1=3\n",
    "]\n",
    "\n",
    "# Training\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for inputs, target in dataset:\n",
    "        loss = rnn.train(inputs, target)\n",
    "        total_loss += loss\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Testing\n",
    "test_input = [np.array([[2]]), np.array([[3]])]  # Should predict 5\n",
    "pred = rnn.predict(test_input)\n",
    "print(\"Prediction for 2+3:\", pred.flatten()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0ec08-fd2f-42b1-ab0f-15f621a75cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
