{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b0a761e0-b094-4a21-9638-bba2acb70722",
   "metadata": {},
   "source": [
    "# Reinforcement learning is about learning from trail and error by interacting with system.\n",
    "# Reward and penality \n",
    "# Learning from rewards and punishement in absense of detailed supervision \n",
    "\n",
    "# Terminalogies : \n",
    "* State : input\n",
    "* Action : action on input using policy \n",
    "* Policy : reward or punishment\n",
    "* Feedback : reward or penality \n",
    "x\n",
    "# Agent intracts with environment\n",
    "* Agent and Environment\n",
    "# starting from the current state what will be the output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d34bd-e362-4b8d-b1bf-2910a93457fa",
   "metadata": {},
   "source": [
    "# Reinforcement Learning : \n",
    "\n",
    "# Steps :\n",
    "1) Agent : Intreacts with environment. \n",
    "2) Action : Agent takes action. \n",
    "3) State : Action changes states.\n",
    "4) Rewards  || Punishment : Action gives reward or gives punishment.\n",
    "5) Policy : Policy is an algorithm that tells what action to take in any given sitation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "021ea98a-93f1-44e1-ac1d-1286d30297fa",
   "metadata": {},
   "source": [
    "Week 1\n",
    "Introduction to RL\n",
    "Completed\n",
    "RL Framework and Applications\n",
    "Completed\n",
    "Introduction to Immediate RL\n",
    "Completed\n",
    "Bandit Optimalities\n",
    "Completed\n",
    "Value Function Based Methods\n",
    "Completed\n",
    "Week 1 Feedback Form : Reinforcement Learning\n",
    "Completed\n",
    "Practice: Week 1 : Assignment 1(Non Graded)\n",
    "Not Started\n",
    "Quiz: Week 1 : Assignment 1\n",
    "Completed\n",
    "Week 1 solution\n",
    "Completed\n",
    "\n",
    "\n",
    "Week 2\n",
    "UCB 1\n",
    "Completed\n",
    "Concentration Bounds\n",
    "Completed\n",
    "UCB 1 Theorem\n",
    "Completed\n",
    "PAC Bounds\n",
    "Completed\n",
    "Median Elimination\n",
    "Completed\n",
    "Thompson Sampling\n",
    "Completed\n",
    "Week 2 Feedback Form : Reinforcement Learning\n",
    "Not Started\n",
    "Week 2: Solutions\n",
    "Completed\n",
    "Quiz: Week 2 : Assignment 2\n",
    "Completed\n",
    "\n",
    "\n",
    "Week 3\n",
    "Policy Search\n",
    "Completed\n",
    "REINFORCE\n",
    "Completed\n",
    "Contextual Bandits\n",
    "Completed\n",
    "Full RL Introduction\n",
    "Completed\n",
    "Returns, Value Functions and MDPs\n",
    "Completed\n",
    "Week 3 Feedback Form : Reinforcement Learning!!\n",
    "Not Started\n",
    "Week 3: Solutions\n",
    "Not Started\n",
    "Quiz: Week 3 : Assignment 3\n",
    "Completed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Week 4\n",
    "MDP Modelling\n",
    "Not Started\n",
    "Bellman Equation\n",
    "Not Started\n",
    "Bellman Optimality Equation\n",
    "Not Started\n",
    "Cauchy Sequence and Green's Equation\n",
    "Not Started\n",
    "Banach Fixed Point Theorem\n",
    "Not Started\n",
    "Convergence Proof\n",
    "Not Started\n",
    "Week 4 Feedback Form : Reinforcement Learning\n",
    "Completed\n",
    "Quiz: Week 4 : Assignment 4\n",
    "Completed\n",
    "Week 4 : Solution\n",
    "Not Started\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Week 5\n",
    "Lpi Convergence\n",
    "Not Started\n",
    "Value Iteration\n",
    "Not Started\n",
    "Policy Iteration\n",
    "Not Started\n",
    "Dynamic Programming\n",
    "Not Started\n",
    "Monte Carlo\n",
    "Not Started\n",
    "Control in Monte Carlo\n",
    "Not Started\n",
    "Week 5 Feedback Form : Reinforcement Learning!!\n",
    "Not Started\n",
    "Quiz: Week 5 : Assignment 5\n",
    "Completed\n",
    "Week 5 : Solutions\n",
    "Completed\n",
    "\n",
    "\n",
    "\n",
    "Week 6\n",
    "Off Policy MC\n",
    "Not Started\n",
    "UCT\n",
    "Not Started\n",
    "TD(0)\n",
    "Not Started\n",
    "TD(0) Control\n",
    "Not Started\n",
    "Q-Learning\n",
    "Not Started\n",
    "Afterstate\n",
    "Not Started\n",
    "Week 6 Feedback Form:Reinforcement Learning!!\n",
    "Not Started\n",
    "Week 6: Solutions\n",
    "Not Started\n",
    "Quiz: Week 6 : Assignment 6\n",
    "Completed\n",
    "Week 7\n",
    "Eligibility Traces\n",
    "Not Started\n",
    "Backward View of Eligibility Traces\n",
    "Not Started\n",
    "Eligibility Trace Control\n",
    "Not Started\n",
    "Thompson Sampling Recap\n",
    "Not Started\n",
    "Week 7 Feedback Form:Reinforcement Learning!!\n",
    "Not Started\n",
    "Quiz: Week 7 : Assignment 7\n",
    "Completed\n",
    "Week 7: Solutions\n",
    "Not Started\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Week 8\n",
    "Function Approximation\n",
    "Not Started\n",
    "Linear Parameterization\n",
    "Not Started\n",
    "State Aggregation Methods\n",
    "Not Started\n",
    "Function Approximation and Eligibility Traces\n",
    "Not Started\n",
    "LSTD and LSTDQ\n",
    "Not Started\n",
    "LSPI and Fitted Q\n",
    "Not Started\n",
    "Week 8 Feedback Form : Reinforcement Learning\n",
    "Not Started\n",
    "Quiz: Week 8 : Assignment 8\n",
    "Completed\n",
    "Week 8: Solutions\n",
    "Not Started\n",
    "\n",
    "\n",
    "\n",
    "Week 9\n",
    "DQN and Fitted Q-Iteration\n",
    "Not Started\n",
    "Policy Gradient Approach\n",
    "Not Started\n",
    "Actor Critic and REINFORCE\n",
    "Not Started\n",
    "REINFORCE (cont'd)\n",
    "Not Started\n",
    "Policy Gradient with Function Approximation\n",
    "Not Started\n",
    "Week 9 Feedback Form : Reinforcement Learning\n",
    "Not Started\n",
    "Quiz: Week 9 : Assignment 9\n",
    "Completed\n",
    "Week 9: Solutions\n",
    "Not Started\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Week 10\n",
    "Hierarchical Reinforcement Learning\n",
    "Not Started\n",
    "Types of Optimality\n",
    "Not Started\n",
    "Semi Markov Decision Processes\n",
    "Not Started\n",
    "Options\n",
    "Not Started\n",
    "Learning with Options\n",
    "Not Started\n",
    "Hierarchical Abstract Machines\n",
    "Not Started\n",
    "Week 10 Feedback Form : Reinforcement Learning\n",
    "Not Started\n",
    "Week 10: Solutions\n",
    "Not Started\n",
    "Quiz: Week 10 : Assignment 10\n",
    "Completed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Week 11\n",
    "MAXQ\n",
    "Not Started\n",
    "MAXQ Value Function Decomposition\n",
    "Not Started\n",
    "Option Discovery\n",
    "Not Started\n",
    "Week 11 Feedback Form : Reinforcement Learning\n",
    "Not Started\n",
    "Week 11: Solutions\n",
    "Not Started\n",
    "Quiz: Week 11 : Assignment 11\n",
    "Completed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Week 12\n",
    "POMDP Introduction\n",
    "Not Started\n",
    "Solving POMDP\n",
    "Not Started\n",
    "Week 12 Feedback Form : Reinforcement Learning\n",
    "Not Started\n",
    "Week 12: Solutions\n",
    "Not Started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114d2d2e-602e-49ce-b782-538aab3fc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy : Defines what to do in given state or which action to take in the given state.\n",
    "# Action : gives us an output that is good or bad (reward) \n",
    "# Value function : Gives the Expected fulutre reward by taking the action in the given state using the given policy \n",
    "# Discount Factor : How important the future rewards are it's from 0-1 0 means not at all important 1 means are bit important and .5 means balanced between them.\n",
    "# State : The part of an environment \n",
    "# Reward | penalities : The immediate or long term output of an action.\n",
    "# Define Policy → 2. Evaluate Policy → 3. Improve Policy → Repeat until the policy converges.\n",
    "# episode : Entire tragectory of steps from start to end is considered as one step. We talk about cumulative rewards in episodic learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef998c2-6e86-4025-aea7-0cea23181a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms in reinforcement learning : \n",
    "# Dynamic programming : Not feasible for a problem with large sample space & also doesnot work on partially observable environment.\n",
    "# monte-carlo method : They can work on any partial observable environment or completely observable environment.\n",
    "\n",
    "\n",
    "# Two main approaches to solve reinforcment learning problems : \n",
    "# MDP : Markovs decision process \n",
    "# POMDP : Partially Observable Markovs Decision Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95ef2b8-98e3-4529-94bd-8676ef9ba7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montecarlo \n",
    "# Temporal difference \n",
    "# SARSA\n",
    "# Q-Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7a1d5-e825-4f64-be0a-513cc582a0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
